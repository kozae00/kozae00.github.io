---
title: 포로메테우스 & 그라파나
author: kozae00
category: Jekyll
layout: post
---
### What is Promethus ?

**'프로메테우스'란❓** 
Metric 수집, 시각화, 알림, 서비스 디스커버리 기능을 모두 제공하는 오픈 소스 모니터링 시스템

- 풀 방식의 메트릭스 수집, 시계열 데이터 저장
>💡 **풀방식이란❓** 설정된 간격으로 각 모니터링 대상의 HTTP 엔드포인트를 정기적으로 조회하여 데이터를 가져오는 방식

- PromQL을 활용하여 저장된 시계열 쿼리 및 집계
> 💡 **PromQL❓**Prometheus Query

- 서비스 디스커버리
- 데이터 시각화

---
### What is Grafana ?

**'그라파나'란 ❓** 시계열 메트릭 데이터를 시각화하는데 가장 최적화된 대시보드를 제공해주는 오픈소스툴 킷

- Prometheus / ElasticSearch 등 여러 데이터 소스와 통합 가능
- 시각화한 그래프에서 특정 수치 이상으로 값이 치솟을 때 알림을 전달 받을 수 있는 기능
- 인프라 운영관점에서 굉장히 중요한 기능

---
### Prometheus Architecture

![[프로메테우스 아키텍처.png]]

### 🧾Component(요소)

**☑️ Prometheus Server**
- Metric을 수집하고 저장하며, 쿼리를 처리하는 중앙 컴포넌트
- Retrieval : 데이터를 **수집**
  ➡️ 모두 Pull 방식으로 수집
- Storage : 데이터 **저장**
- PromQL : **쿼리**를 통해 작업 수행

**☑️ Pushgateway**
- shorted-lived jobs에서 push한 데이터를 가지고 있음
>💡 **shorted-lived jobs란❓**실행 후 빠르게 종료되는 job (CronJob, BatchJob 등)

- Prometheus가 pushgateway에 있는 데이터를 pull해서 scrap함
  ➡️ scrap한 데이터는 prometheus **로컬에 저장**
  ➡️ prometheus는 **로컬 스토리지 기반의 서버**

**☑️ Service Discovery**
- **Metric 데이터를 동적**으로 **수집**할 때 Service Discovery 프로그램과 **연동**해야 함.
> 💡MSA로 구성되어 있는 서비스들은 각자 IP와 Port를 가지고 있는데 이러한 서로 다른 서비스들의 IP와 Port 정보에 대해서 저장하고 관리할 필요가 있어서 이것을 관리하는 것이 Service Discovery라고 함.

1.  **Kubernetes**
   - End point : Kubernetes의 Service가 연결된 Pod의 엔드포인트
   - Pod : 개별 Pod에서 직접 메트릭을 노출하는 경우
   - Services : 특정 서비스에서 메트릭을 제공하는 경우
   - Nodes : Kubernetes의 노드 자체의 메트릭을 가져올 때
2. **EC2**
   - CPU 사용량
   - 메모리 사용량
   - 네트워크 트래픽
3. ETC 등 ...

- **prometheus.yml**
```yaml
global:
	scrape_interval: 15s
	evalutaion_interval: 15s

alerting:
	alertmanager:
		- static_configs:
			- targets:

rule_files:
	# ~~~.yml
	# ~~~.yml

scrape_configs:
	- job_name: "prometheus"
		static_configs:
			- targets: ["172.30.3.166:9090"]
			
	- job_name: "node"
		file_sd_configs:
			- files:
				- "target_node.json"
```

- **target_node.json**
```json
[
	{
		"targets" : [
			"172.30.3.170:9100",
			"172.30.3.176:9100"
		],
		"labels" : {
			"group" : "production"
		}
	},
	{
		"targets" : [
			"172.30.3.177:9100"
		],
		"labels" : {
			"group" : "develop"
		}
	}
]
```

>🔖**Ref** : [Prometheus Service Discovery 파일 기반 Config 파일 작성하기](https://magpienote.tistory.com/263)

**☑️ Exporters**
- 모니터링 대상의 Metric 정보를 수집
- 대상 시스템과 Prometheus 사이의 중개자 역할
- Exporter가 직접 데이터를 수집할 수 없는 외부 시스템의 Metric을 반환하여 Prometheus가 이해할 수 있도록 제공하는 컴포넌트
  ➡️ 메트릭을 스크래핑할 수 있도록 **HTTP 엔드포인트를 노출함**.

```java
@Component
public class CustomMetricExporter {

    private final AtomicInteger customValue = new AtomicInteger(0);
    private final MeterRegistry meterRegistry;

    public CustomMetricExporter(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
    }

    @PostConstruct
    public void init() {
        Gauge.builder("custom_metric_example", customValue, AtomicInteger::get)
                .description("An example custom metric")
                .register(meterRegistry);

        // 백그라운드로 값 계속 변경
        new Thread(() -> {
            while (true) {
                customValue.set((int) (Math.random() * 100));
                try {
                    Thread.sleep(5000); // 5초마다 업데이트
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
        }).start();
    }
}
```

Spring Boot 앱을 실행한 뒤, `http://localhost:8080/actuator/prometheus`에서 Metric 확인 가능

**☑️ Alter Manager**
- Prometheus에서 생성된 알림을 처리함.
- 알림을 라우팅, 그룹화 및 처리 기능하며, email, 채팅 플랫폼 또는 인시던트 관리 시스템과 같은 다양한 알림 채널로 보낼 수 있음.

>🔖 **Ref** : [AlertManager + Slack Hook 설정](https://velog.io/@91savage/Prometheus-AlertManager-Slack-Hook-%EC%84%A4%EC%A0%95)

---
### Prom QL example

**☑️ Prometheus Data Type**
- Instant Vecotr
> 같은 time stamp에 있는 Time Series 집합
> 각 Time Series 마다 단일 샘플을 가지고 있음
> metric 이름으로 쿼리를 실행하면 Instant Vecotr를 얻을 수 있고,
> 필터링을 하고 싶으면 Instant Selector를 사용함.

- Range Vecotr
> 특정 시간 범위에 있는 Time Series set.
> Instant Vector는 각 time-series들이 1개의 Sample만 가지는 것에 반해, Range Vecotr는 지정된 범위의 시간에 속하는 Time Series들로 구성되어 있다.

- Scalar
> 시간 정보가 없는 값. 단순한 숫자

- String
> 문자열 데이터, 실제로 사용은 되지 않음.

---
### + AI/ML Monitoring With Prometheus

**☑️ AI/ML Monitoring With Prometheus**
![[AI모니터링 with 프로메테우스.png]]
> **Model의 배포**까지 성공했다면? 그 다음 단계는?
> 그 것은 바로 배포한 모델이 우리의 의도대로 동작하고 있는 지에 대한 확인이다.
> **모델 자체가 불완전하지는 않은 지 등 사전에 고려하지 못한 이슈를 발견**하고 해결하기 위해 우리는 모델을 모니터링 할 필요가 있다. 

 **☑️1. AI/ML 에서 모니터링의 중요성**
 1-1. 문제의 조기 감지
- 모니터링을 통해 모델 성능 저하에서 데이터 파이프라인 오류에 이르기까지 문제를 조기에 식별 가
  ➡️ 조기 감지를 통해 더 바른 대응 및 운영 효율성에 상당한 영향을 미칠 위험을 줄임.
 
 1-2. 리소스 사용 추적
 - CPU / Memory / Storage 활용도와 같은 계산 리소스를 파악하는 것은 비용 효율적인 운영에 필수적
   ➡️ 이러한 지표 모니터링하면 리소스 할당 및 확장 전략을 최적화하는데 도움.
 
 1-3. 데이터 드리프트 감지
 - 시간 경과에 따른 데이터 분포의 변화, 즉 데이터 드리프트는 모델 성능에 부정적인 영향을 미칠 수 있음. 
>💡**데이터 드리프트❓** 학습용 데이터와 인퍼런스 시점의 실시간 데이터를 비교하여 데이터의 분포 차이 감지
>💡**인퍼런스 시점 데이터❓** 모델이 서비스 환경에서 실제로 예측할 때 입력 받는 데이터


**☑️ 2. Model Monitoring**

>💡 **Model Monitoring**❓"Serving한 모델의 지속 가능한 운영을 위한 관리"로 정리 가능
- 그렇다면 어떤 모니터링을 정의해야 하는가???

>💡 Model Monitoring이 포함해야 할 **구성 요소**
>- 모델이 수치적으로 안정적인가?
>- 모델이 느려지고 있지 않은가?
>- 모델이 serving에서의 데이터에 대해 잘 예측하는가?
>- 모델 업데이트는 필요 없는가?
>- 등 ...

**ML Ops 측면에서의 Monitoring 대상 요소**
- **ML**
	- Input Data Distribution
	  ➡️ Input Data 분포
	- Feature Distribution
	  ➡️ 특징 분포
	- Output Data Distribution
	- Performance
	  ➡️ 성능
	- Model Stability
	  ➡️ 모델 안정성
- **Ops**
	- Request Latency
	  ➡️ 리퀘스트 지연 시간
	- Request Error Rate
	- CPU, Memory Utilization
	- Disk I/O
	- Network Traffic
	  ➡️ 네트워크 트래픽
	
>💡 해당 AI 모델을 serving하면 모델의 크기에 따라 Service 속도에서 차이가 날 수 있기에 모델의 안정성 및 모델이 처리하는 시간 등 Ops와 함께 같이 모니터링 해야 한다.

ex) : AI/ML 모델이 크다면? 연산량이 많아지므로 Service 측면에서 사용자들이 오래 기다려야하는 문제가 생긴다.